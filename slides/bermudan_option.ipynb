{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32be14f1-36f4-40ea-a154-87d0224370ac",
   "metadata": {},
   "source": [
    "# OpenGRIS Scaler Demo With Multiple Backends (IBM Symphony + AWS ECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e853b2f-4b1f-4c70-a173-7147f404d5aa",
   "metadata": {},
   "source": [
    "## Example: Heston model Bermudan call option pricing using Monte Carlo simulation\n",
    "\n",
    "A Bermudan option is an exotic option exercisable on predetermined dates, usually monthly. It differs from European options which can only be exercised on the date of expiration and American options which can be exercised at any time before expiration.\n",
    "\n",
    "Given a basket of stocks, download price data from Yahoo finance and use the Heston model to price a Bermudan call option using Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b780bb4-941b-41ab-89f2-58c5b9a493a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import logging\n",
    "from time import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from scaler import Client\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acb2c8-f107-40bf-aae9-4b7eb6a39702",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cfdecf-1b89-42a7-b570-fb02741a4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\n",
    "    'NVDA', 'MSFT', 'AAPL', 'GOOGL', 'AMZN', 'META', 'AVGO', '2222.SR',\n",
    "    'TSLA', 'TSM', 'BRK-B', 'ORCL', 'WMT', 'JPM', 'TCEHY', 'LLY',\n",
    "    'V', 'NFLX', 'MA', 'XOM'\n",
    "]\n",
    "\n",
    "HESTON_DEFAULTS = {\n",
    "    'kappa': 2.0,\n",
    "    'theta': 0.04,\n",
    "    'sigma': 0.3,\n",
    "    'rho': -0.7,\n",
    "    'v0': 0.04,\n",
    "}\n",
    "\n",
    "r_default = 0.05\n",
    "q = 0.0\n",
    "basis_degree = 3\n",
    "barrier_frac = 1.0\n",
    "\n",
    "scheduler_address=\"tcp://127.0.0.1:8080\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc4e1c-cc24-45da-8f1c-e3d6775aa234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download, Generate Tasks, Calculate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99acc15-c51b-422c-9042-dec369b8da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_prices(tickers, start, end):\n",
    "    data = yf.download(tickers, start=start, end=end, auto_adjust=False)['Adj Close']\n",
    "    last_prices = data.iloc[-1].values\n",
    "    returns = np.log(data / data.shift(1)).dropna()\n",
    "    corr_matrix = np.corrcoef(returns.T)\n",
    "    np.fill_diagonal(corr_matrix, 1.0)\n",
    "    logger.info(f\"Last prices: {dict(zip(tickers, last_prices))}\")\n",
    "    return last_prices, corr_matrix\n",
    "\n",
    "\n",
    "def generate_one_path_using_rng(S0, corr_chol, dt, num_steps, heston, rng):\n",
    "    \"\"\"\n",
    "    Generate one path using a provided numpy.random.Generator 'rng' (so it's safe to call\n",
    "    in different processes with controlled seeding).\n",
    "    Returns array shape (num_steps+1, n_assets)\n",
    "    \"\"\"\n",
    "    n = len(S0)\n",
    "    S = np.zeros((num_steps + 1, n))\n",
    "    V = np.zeros((num_steps + 1, n))\n",
    "    S[0] = S0\n",
    "    V[0] = heston['v0']\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    rho = heston['rho']\n",
    "    sqrt_1mrho2 = np.sqrt(max(0, 1 - rho**2))\n",
    "    kappa = heston['kappa']\n",
    "    theta = heston['theta']\n",
    "    sigma_v = heston['sigma']\n",
    "\n",
    "    for t in range(1, num_steps + 1):\n",
    "        Z_stock = rng.standard_normal(n)\n",
    "        dW_stock = corr_chol @ Z_stock * sqrt_dt\n",
    "        Z_vol_ind = rng.standard_normal(n) * sqrt_dt\n",
    "        dW_vol = rho * dW_stock + sqrt_1mrho2 * Z_vol_ind\n",
    "        drift_s = (r_default - q - 0.5 * V[t - 1]) * dt\n",
    "        S[t] = S[t - 1] * np.exp(drift_s + np.sqrt(np.maximum(V[t - 1], 0)) * dW_stock)\n",
    "        drift_v = kappa * (theta - V[t - 1]) * dt\n",
    "        vol_sqrtv = sigma_v * np.sqrt(np.maximum(V[t - 1], 0))\n",
    "        V[t] = np.maximum(V[t - 1] + drift_v + vol_sqrtv * dW_vol, 1e-6)\n",
    "    return S\n",
    "\n",
    "\n",
    "def generate_paths_batch(num_paths_batch, S0, corr_chol, dt, num_steps, heston, seed=None):\n",
    "    \"\"\"\n",
    "    Worker function for distributed execution. Generates 'num_paths_batch' paths and returns\n",
    "    a numpy array with shape (num_paths_batch, num_steps+1, n_assets).\n",
    "    This function is picklable and safe to submit to the scaler.Client.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    batch = []\n",
    "    for i in range(num_paths_batch):\n",
    "        path = generate_one_path_using_rng(S0, corr_chol, dt, num_steps, heston, rng)\n",
    "        batch.append(path)\n",
    "    return np.stack(batch, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def generate_many_path_tasks(num_paths, S0, corr_chol, dt, num_steps, heston, batch_size):\n",
    "    \"\"\"\n",
    "    Use scaler.Client to submit batches of path generation as separate tasks.\n",
    "    - batch_size controls how many paths each submitted job generates.\n",
    "    - show_progress toggles a tqdm bar for completed batches.\n",
    "    Returns stacked paths array shape (num_paths, num_steps+1, n_assets)\n",
    "    \"\"\"\n",
    "    # Compute batches\n",
    "    num_batches = (num_paths + batch_size - 1) // batch_size\n",
    "    batches = []\n",
    "    # compute exact sizes for each batch (last may be smaller)\n",
    "    batch_sizes = [batch_size] * num_batches\n",
    "    last_mod = num_paths - batch_size * (num_batches - 1)\n",
    "    batch_sizes[-1] = last_mod if last_mod > 0 else batch_size\n",
    "\n",
    "    base_seed = int(time()) & 0x7FFFFFFF\n",
    "    \n",
    "    tasks = []\n",
    "    for i, bs in enumerate(batch_sizes):\n",
    "        seed = base_seed + i\n",
    "        tasks.append((generate_paths_batch, (bs, S0, corr_chol, dt, num_steps, heston, seed)))\n",
    "        \n",
    "    return tasks\n",
    "\n",
    "\n",
    "def price_bermudan(paths, K, barrier, r, exercise_indices, ex_times, degree):\n",
    "    num_paths, num_steps, n_assets = paths.shape\n",
    "    basket_paths = np.mean(paths, axis=2)\n",
    "    basket_ex = basket_paths[:, exercise_indices]\n",
    "    num_ex = basket_ex.shape[1]\n",
    "    hit_mask = basket_ex < barrier\n",
    "    has_hit = np.any(hit_mask, axis=1)\n",
    "    first_hit_idx = np.argmax(hit_mask, axis=1)\n",
    "    first_hit_idx[~has_hit] = num_ex\n",
    "    cashflow = np.zeros(num_paths)\n",
    "    alive_at_last = first_hit_idx == num_ex\n",
    "    cashflow[alive_at_last] = np.maximum(basket_ex[alive_at_last, -1] - K, 0)\n",
    "    for j in range(num_ex - 2, -1, -1):\n",
    "        delta_t_j = ex_times[j + 1] - ex_times[j]\n",
    "        disc_factor = np.exp(-r * delta_t_j)\n",
    "        alive = first_hit_idx > j\n",
    "        num_alive = np.sum(alive)\n",
    "        if num_alive == 0:\n",
    "            continue\n",
    "        disc_cash_next = disc_factor * cashflow[alive]\n",
    "        basket_j = basket_ex[alive, j]\n",
    "        itm = basket_j > K\n",
    "        num_itm = np.sum(itm)\n",
    "        if num_itm < degree + 1:\n",
    "            cont = np.full(num_alive, np.mean(disc_cash_next))\n",
    "        else:\n",
    "            X = np.vander(basket_j[itm], degree + 1, increasing=True)\n",
    "            y = disc_cash_next[itm]\n",
    "            beta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "            X_all = np.vander(basket_j, degree + 1, increasing=True)\n",
    "            cont = X_all @ beta\n",
    "        intrinsic = np.maximum(basket_j - K, 0)\n",
    "        exercise = intrinsic > cont\n",
    "        exercised_idx = np.where(alive)[0][exercise]\n",
    "        cashflow[exercised_idx] = intrinsic[exercise]\n",
    "    price = np.mean(np.exp(-r * ex_times[-1]) * cashflow)\n",
    "    print(f\"The price of the Bermudan down-and-out call option on the equally-weighted basket is {price:.4f}\")\n",
    "    return price\n",
    "\n",
    "\n",
    "def generate_tasks(start_date, end_date, num_paths, num_steps, maturity, num_exercises,\n",
    "                   risk_free_rate, batch_size):\n",
    "    \"\"\"\n",
    "    Main entry. Set use_distributed=True to use scaler.Client and submit batch jobs.\n",
    "    \"\"\"\n",
    "    global r_default\n",
    "    r_default = risk_free_rate\n",
    "\n",
    "    S0, corr = download_prices(TICKERS, start_date, end_date)\n",
    "    try:\n",
    "        corr_chol = np.linalg.cholesky(corr)\n",
    "    except np.linalg.LinAlgError:\n",
    "        logger.warning(\"Correlation matrix not positive semi-definite, adding jitter.\")\n",
    "        corr += np.eye(corr.shape[0]) * 1e-6\n",
    "        corr_chol = np.linalg.cholesky(corr)\n",
    "\n",
    "    basket0 = np.mean(S0)\n",
    "    K = basket0\n",
    "    barrier = barrier_frac * K\n",
    "    dt = maturity / num_steps\n",
    "    step_per_period = num_steps // num_exercises\n",
    "    exercise_indices = np.arange(1, num_exercises + 1) * step_per_period\n",
    "    exercise_indices = exercise_indices[exercise_indices <= num_steps]\n",
    "    ex_times = exercise_indices * dt\n",
    "    heston = HESTON_DEFAULTS\n",
    "\n",
    "    tasks = generate_many_path_tasks(num_paths, S0, corr_chol, dt, num_steps, heston, batch_size=batch_size)\n",
    "    return K, barrier, r_default, exercise_indices, ex_times, basis_degree, tasks\n",
    "\n",
    "\n",
    "def get_bermudan_price(K, barrier, r_default, exercise_indices, ex_times, basis_degree, results):\n",
    "    paths = np.concatenate(results, axis=0)\n",
    "    # If we over-allocated for any reason, trim to requested num_paths\n",
    "    # if paths.shape[0] > num_paths:\n",
    "    #     paths = paths[:num_paths]\n",
    "\n",
    "    return price_bermudan(paths, K, barrier, r_default, exercise_indices, ex_times, basis_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd54518c-7d49-4368-b6e9-48b9e4c24ec0",
   "metadata": {},
   "source": [
    "## Generate Task Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d171c5fd-3682-42cb-8b58-c64e23c2729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  20 of 20 completed\n",
      "INFO:__main__:Last prices: {'NVDA': 24.97572135925293, 'MSFT': 247.21035766601562, 'AAPL': 214.47000122070312, 'GOOGL': 354.1499938964844, 'AMZN': 488.80999755859375, 'META': 251.4600067138672, 'AVGO': 298.5400085449219, '2222.SR': 818.1784057617188, 'TSLA': 549.8800048828125, 'TSM': 712.0700073242188, 'BRK-B': 511.6099853515625, 'ORCL': 118.35900115966797, 'WMT': 181.80999755859375, 'JPM': 313.0, 'TCEHY': 79.68000030517578, 'LLY': 428.75, 'V': 299.8399963378906, 'NFLX': 334.7369689941406, 'MA': 106.47000122070312, 'XOM': 109.68067169189453}\n"
     ]
    }
   ],
   "source": [
    "K, barrier, r_default, exercise_indices, ex_times, basis_degree, tasks = generate_tasks(\n",
    "    start_date='2024-10-17', end_date='2025-10-17', num_paths=100_000, num_steps=252, maturity=1.0, num_exercises=12, risk_free_rate=0.05, batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211de5c0-1f53-4ac7-8ce4-f9d6d94cfdfe",
   "metadata": {},
   "source": [
    "## Compute On IBM Symphony Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e084c8c0-1781-43b0-9be1-835ebcdec3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ScalerClient: connect to scheduler at tcp://127.0.0.1:8080\n",
      "INFO:root:ZMQAsyncConnector: started\n",
      "INFO:root:ZMQAsyncConnector: started\n",
      "INFO:root:ClientHeartbeatManager: started\n",
      "INFO:root:ScalerClient: connect to object storage at tcp://127.0.0.1:8081\n",
      "batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:50<00:00, 28.50batch/s]\n",
      "INFO:root:ScalerClient: disconnect from tcp://127.0.0.1:8080\n",
      "INFO:root:canceling 0 task(s)\n",
      "INFO:root:ClientAgent: client quitting\n",
      "INFO:root:ZMQAsyncConnector: exited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the Bermudan down-and-out call option on the equally-weighted basket is 14.5174\n"
     ]
    }
   ],
   "source": [
    "def compute_symphony(scheduler_address, K, barrier, r_default, exercise_indices, ex_times, basis_degree):\n",
    "    with Client(scheduler_address) as client:\n",
    "        # Submit all batch jobs\n",
    "        sym_futures = [client.submit_verbose(*task, kwargs={}, capabilities={\"symphony\": -1}) for task in tasks]\n",
    "    \n",
    "        symphony_result = get_bermudan_price(\n",
    "            K, barrier, r_default, exercise_indices, ex_times, basis_degree,\n",
    "            [sym_futures[idx].result() for idx in tqdm(range(len(sym_futures)), desc=\"batches\", unit=\"batch\")]\n",
    "        )\n",
    "\n",
    "compute_symphony(scheduler_address, K, barrier, r_default, exercise_indices, ex_times, basis_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf405fe3-42ca-4131-b040-5dc7319fddb2",
   "metadata": {},
   "source": [
    "## Compute On AWS ECS Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa742fad-df5c-41db-acdf-491903e869b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ScalerClient: connect to scheduler at tcp://127.0.0.1:8080\n",
      "INFO:root:ZMQAsyncConnector: started\n",
      "INFO:root:ZMQAsyncConnector: started\n",
      "INFO:root:ClientHeartbeatManager: started\n",
      "INFO:root:ScalerClient: connect to object storage at tcp://127.0.0.1:8081\n",
      "batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:29<00:00, 111.57batch/s]\n",
      "INFO:root:ScalerClient: disconnect from tcp://127.0.0.1:8080\n",
      "INFO:root:canceling 0 task(s)\n",
      "INFO:root:ClientAgent: client quitting\n",
      "INFO:root:ZMQAsyncConnector: exited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the Bermudan down-and-out call option on the equally-weighted basket is 14.5174\n"
     ]
    }
   ],
   "source": [
    "def compute_ecs(scheduler_address, K, barrier, r_default, exercise_indices, ex_times, basis_degree):\n",
    "    with Client(scheduler_address) as client:\n",
    "        # Submit all batch jobs\n",
    "        futures = [client.submit_verbose(*task, kwargs={}, capabilities={\"ecs\": -1}) for task in tasks]\n",
    "    \n",
    "        # Gather results with progress\n",
    "        results = [futures[idx].result() for idx in tqdm(range(len(futures)), desc=\"batches\", unit=\"batch\")]\n",
    "        get_bermudan_price(K, barrier, r_default, exercise_indices, ex_times, basis_degree, results)\n",
    "\n",
    "compute_ecs(scheduler_address, K, barrier, r_default, exercise_indices, ex_times, basis_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559bcda-4bfd-4f1f-92a2-fc82c8012514",
   "metadata": {},
   "source": [
    "## Compute on Both IBM Symphony and AWS ECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d78262-982e-4f30-b42a-4395f1ac0df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ScalerClient: connect to scheduler at tcp://127.0.0.1:8080\n",
      "INFO:root:ZMQAsyncConnector: started\n",
      "INFO:root:ZMQAsyncConnector: started\n",
      "INFO:root:ClientHeartbeatManager: started\n",
      "INFO:root:ScalerClient: connect to object storage at tcp://127.0.0.1:8081\n",
      "batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:04<00:00, 27.42batch/s]\n",
      "INFO:root:ScalerClient: disconnect from tcp://127.0.0.1:8080\n",
      "INFO:root:canceling 0 task(s)\n",
      "INFO:root:ClientAgent: client quitting\n",
      "INFO:root:ZMQAsyncConnector: exited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the Bermudan down-and-out call option on the equally-weighted basket is 14.6561\n"
     ]
    }
   ],
   "source": [
    "def compute_both(scheduler_address, K, barrier, r_default, exercise_indices, ex_times, basis_degree):\n",
    "    with Client(scheduler_address) as client:\n",
    "        # Submit all batch jobs\n",
    "        futures = [client.submit_verbose(*task, kwargs={}, capabilities={\"python3\": -1}) for task in tasks]\n",
    "        get_bermudan_price(\n",
    "            K, barrier, r_default, exercise_indices, ex_times, basis_degree,\n",
    "            [futures[idx].result() for idx in tqdm(range(len(futures)), desc=\"batches\", unit=\"batch\")]\n",
    "        )\n",
    "\n",
    "compute_both(scheduler_address, K, barrier, r_default, exercise_indices, ex_times, basis_degree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
